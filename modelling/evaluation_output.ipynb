{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 13:37:09.961917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 13:37:21.466730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-04 13:37:21.468345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-04 13:37:21.468367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "from nltk import word_tokenize, ngrams\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import shutil\n",
    "from nltk import sent_tokenize\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filepaths(dir):\n",
    "    file_paths = {}\n",
    "    titles = [\"head_0\", \"head_1\", \"mixed\"]\n",
    "    for title in titles:\n",
    "        path = os.path.join(dir, title)\n",
    "        path = os.path.join(path,\"test_outfinal.txt\")\n",
    "        file_paths[title] = path\n",
    "    return file_paths\n",
    "def get_paired_outputs(filepath):\n",
    "    paired_outputs = {}\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        cur_index = 0\n",
    "        for index , line in enumerate(lines):\n",
    "            if index % 4 == 0:\n",
    "                paired_outputs[cur_index] = {\"article\": line}\n",
    "            elif index % 4 == 1:\n",
    "                paired_outputs[cur_index][\"reference\"] = line\n",
    "            elif index % 4 == 2:\n",
    "                paired_outputs[cur_index][\"summary\"] = line\n",
    "            elif index % 4 == 3:\n",
    "                cur_index += 1\n",
    "    return paired_outputs\n",
    "def get_rouge_scores(references, candidates):\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    results = rouge.compute(predictions=candidates, references=references)\n",
    "    print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_file(input_dict):\n",
    "\n",
    "    inputs = []\n",
    "    candidates = []\n",
    "    references = []\n",
    "\n",
    "    for key in input_dict.keys():\n",
    "        input = input_dict[key]['article']\n",
    "        gold = input_dict[key]['reference']\n",
    "        summary = input_dict[key]['summary']\n",
    "        input = input.strip()\n",
    "        input = re.sub('<.*?>', '', input)\n",
    "        gold = gold.strip()\n",
    "        gold = re.sub('<.*?>', '', gold)\n",
    "        summary = summary.strip()\n",
    "        summary = re.sub('<.*?>', '', summary)\n",
    "        inputs.append(input)\n",
    "        candidates.append(summary)\n",
    "        references.append(gold)\n",
    "\n",
    "    return inputs, references, candidates\n",
    "\n",
    "\n",
    "\n",
    "def compute_rouge(input_dict):\n",
    "    inputs, references, candidates = read_file(input_dict)\n",
    "    get_rouge_scores(references, candidates)\n",
    "\n",
    "def get_overlap(inp, out, ngram):\n",
    "    grams_inp = set(ngrams(word_tokenize(inp.lower()), ngram))\n",
    "    grams_out = set(ngrams(word_tokenize(out.lower()), ngram))\n",
    "\n",
    "    total = len(grams_out)\n",
    "    common = len(grams_inp.intersection(grams_out))\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return float(common) / float(total)\n",
    "def get_overlap_file(input_dict , output_filename, ngram=2, graph=False):\n",
    "    \"\"\" draws and stores the ngram overlap of the generated and gold summaries with the input \n",
    "        ARGS : \n",
    "            input_dict : input dict where key is index, where each output is of the form article , reference, summary\n",
    "            output_filename : used to store the resulting plot\n",
    "            ngram : the size of the ngram overlap to be considered\n",
    "            graph : whether to draw the graph or not\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    overlap_gold = []\n",
    "    overlap_gen = []\n",
    "    gen_length = []\n",
    "    gold_length = []\n",
    "\n",
    "    for key in input_dict.keys():\n",
    "        inp = input_dict[key]['article']\n",
    "        gold = input_dict[key]['reference']\n",
    "        out = input_dict[key]['summary']\n",
    "\n",
    "\n",
    "        overlap_gold.append(get_overlap(inp, gold, ngram))\n",
    "        overlap_gen.append(get_overlap(inp, out, ngram))\n",
    "\n",
    "        gen_length.append(len(out.split(' ')))\n",
    "        gold_length.append(len(gold.split(' ')))\n",
    "\n",
    "\n",
    "    overlap_gold_mean = np.mean(overlap_gold)\n",
    "    overlap_gen_mean = np.mean(overlap_gen)\n",
    "    gen_length = np.mean(gen_length)\n",
    "    gold_length = np.mean(gold_length)\n",
    "\n",
    "\n",
    "    #print(f'Gold overlap %dgram = %f' % (ngram, overlap_gold_mean))\n",
    "    print(f'Generated overlap %dgram = %f' % (ngram, overlap_gen_mean))\n",
    "\n",
    "    #print(f'Gold length = %f' % gold_length)\n",
    "    print(f'Generated length = %f' % gen_length)\n",
    "\n",
    "    if graph:\n",
    "        # the histogram of the data\n",
    "        kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=80)\n",
    "\n",
    "        weights = np.ones_like(overlap_gold) / float(len(overlap_gold))\n",
    "        plt.hist(overlap_gold, **kwargs, label='gold', weights=weights)\n",
    "\n",
    "        weights = np.ones_like(overlap_gen) / float(len(overlap_gold))\n",
    "        plt.hist(overlap_gen, **kwargs, label='generated', weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "        plt.xlabel(f'{ngram}-gram overlap')\n",
    "        plt.ylim(0, 8)\n",
    "        #plt.xlim(0, 1)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(output_filename)\n",
    "        plt.clf()\n",
    "    return overlap_gold, overlap_gen\n",
    "def generate_results(exp_name = \"exp_0\"):\n",
    "    # print the experiment \n",
    "    print(\"experiment name : \" + str(exp_name))\n",
    "    head_0_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/head_0/test_outfinal.txt\")\n",
    "    head_1_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/head_1/test_outfinal.txt\")\n",
    "    mixed_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/mixed/test_outfinal.txt\")\n",
    "    #filepaths = get_all_filepaths(\"outputs/exp_3\")\n",
    "    #head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "    #head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "    #mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "    print(\"gold statistic\")\n",
    "    print(\"gold overlap : {0} and gold length : {1}\".format(0.44, 0.14))\n",
    "\n",
    "    print(\"for head 0 \")\n",
    "    compute_rouge(head_0_outputs)\n",
    "    head_0_overlap_gold, head_0_overlap_gen = get_overlap_file(head_0_outputs, \"./outputs/\" + str(exp_name) + \"/head_0_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"for head 1\")\n",
    "    compute_rouge(head_1_outputs)\n",
    "    head_1_overlap_gold, head_1_overlap_gen = get_overlap_file(head_1_outputs, \"./outputs/\" + str(exp_name) + \"/head_1_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"for mixed\")\n",
    "    compute_rouge(mixed_outputs)\n",
    "    mixed_overlap_gold, mixed_overlap_gen = get_overlap_file(mixed_outputs, \"./outputs/\" + str(exp_name) + \"/mixed_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"---------------------------------- Done ----------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    # print(\"head 0\")\n",
    "    # head_0_overlap_gold, head_0_overlap_gen = get_overlap_file(head_0_outputs, \"./outputs/\" + str(exp_name) + \"/head_0_overlap.jpg\", ngram = 2, graph = True)\n",
    "    # print(\"head 1\")\n",
    "    # head_1_overlap_gold, head_1_overlap_gen = get_overlap_file(head_1_outputs, \"./outputs/\" + str(exp_name) + \"/head_1_overlap.jpg\", ngram = 2, graph = True)\n",
    "    # print(\"mixed\")\n",
    "    # mixed_overlap_gold, mixed_overlap_gen = get_overlap_file(mixed_outputs, \"./outputs/\" + str(exp_name) + \"/mixed_overlap.jpg\", ngram = 2, graph = True)\n",
    "    \n",
    "    kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=80)\n",
    "\n",
    "    weights = np.ones_like(head_0_overlap_gen) / float(len(head_0_overlap_gold))\n",
    "    plt.hist(head_0_overlap_gen, **kwargs, label='head_0', weights=weights)\n",
    "\n",
    "    weights = np.ones_like(head_1_overlap_gen) / float(len(head_1_overlap_gold))\n",
    "    plt.hist(head_1_overlap_gen, **kwargs, label='head_1', weights=weights)\n",
    "\n",
    "    weights = np.ones_like(mixed_overlap_gen) / float(len(mixed_overlap_gold))\n",
    "    plt.hist(mixed_overlap_gen, **kwargs, label='mixed', weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel(f'{2}-gram overlap')\n",
    "    plt.ylim(0, 8)\n",
    "    #plt.xlim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"./outputs/\" + str(exp_name) + \"/combined_overlap.jpg\")\n",
    "    plt.clf()\n",
    "    return head_0_overlap_gold, head_0_overlap_gen, head_1_overlap_gold, head_1_overlap_gen, mixed_overlap_gold, mixed_overlap_gen\n",
    "def do_experiments(list_of_experiments):\n",
    "    for exp in list_of_experiments:\n",
    "        results = generate_results(exp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(exp_name = \"exp_0\"):\n",
    "    # print the experiment \n",
    "    print(\"experiment name : \" + str(exp_name))\n",
    "    head_0_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/head_0/test_outfinal.txt\")\n",
    "    head_1_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/head_1/test_outfinal.txt\")\n",
    "    mixed_outputs = get_paired_outputs(\"./outputs/\" + str(exp_name) + \"/mixed/test_outfinal.txt\")\n",
    "    #filepaths = get_all_filepaths(\"outputs/exp_3\")\n",
    "    #head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "    #head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "    #mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "    print(\"gold statistic\")\n",
    "    print(\"gold overlap : {0} and gold length : {1}\".format(0.44, 0.14))\n",
    "\n",
    "    print(\"for head 0 \")\n",
    "    compute_rouge(head_0_outputs)\n",
    "    head_0_overlap_gold, head_0_overlap_gen = get_overlap_file(head_0_outputs, \"./outputs/\" + str(exp_name) + \"/head_0_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"for head 1\")\n",
    "    compute_rouge(head_1_outputs)\n",
    "    head_1_overlap_gold, head_1_overlap_gen = get_overlap_file(head_1_outputs, \"./outputs/\" + str(exp_name) + \"/head_1_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"for mixed\")\n",
    "    compute_rouge(mixed_outputs)\n",
    "    mixed_overlap_gold, mixed_overlap_gen = get_overlap_file(mixed_outputs, \"./outputs/\" + str(exp_name) + \"/mixed_overlap.jpg\", ngram = 2, graph = True)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"---------------------------------- Done ----------------------------------\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    # print(\"head 0\")\n",
    "    # head_0_overlap_gold, head_0_overlap_gen = get_overlap_file(head_0_outputs, \"./outputs/\" + str(exp_name) + \"/head_0_overlap.jpg\", ngram = 2, graph = True)\n",
    "    # print(\"head 1\")\n",
    "    # head_1_overlap_gold, head_1_overlap_gen = get_overlap_file(head_1_outputs, \"./outputs/\" + str(exp_name) + \"/head_1_overlap.jpg\", ngram = 2, graph = True)\n",
    "    # print(\"mixed\")\n",
    "    # mixed_overlap_gold, mixed_overlap_gen = get_overlap_file(mixed_outputs, \"./outputs/\" + str(exp_name) + \"/mixed_overlap.jpg\", ngram = 2, graph = True)\n",
    "    \n",
    "    kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=80)\n",
    "\n",
    "    weights = np.ones_like(head_0_overlap_gen) / float(len(head_0_overlap_gold))\n",
    "    plt.hist(head_0_overlap_gen, **kwargs, label='head_0', weights=weights)\n",
    "\n",
    "    weights = np.ones_like(head_1_overlap_gen) / float(len(head_1_overlap_gold))\n",
    "    plt.hist(head_1_overlap_gen, **kwargs, label='head_1', weights=weights)\n",
    "\n",
    "    weights = np.ones_like(mixed_overlap_gen) / float(len(mixed_overlap_gold))\n",
    "    plt.hist(mixed_overlap_gen, **kwargs, label='mixed', weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel(f'{2}-gram overlap')\n",
    "    plt.ylim(0, 8)\n",
    "    #plt.xlim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"./outputs/\" + str(exp_name) + \"/combined_overlap.jpg\")\n",
    "    plt.clf()\n",
    "    return head_0_overlap_gold, head_0_overlap_gen, head_1_overlap_gold, head_1_overlap_gen, mixed_overlap_gold, mixed_overlap_gen\n",
    "def do_experiments(list_of_experiments):\n",
    "    for exp in list_of_experiments:\n",
    "        results = generate_results(exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment name : baseline_div_loss_0\n",
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15126413389825547, 'rouge2': 0.05910292822933239, 'rougeL': 0.11993000124746361, 'rougeLsum': 0.11989552981766322}\n",
      "Generated overlap 2gram = 0.747915\n",
      "Generated length = 86.587705\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.26261168309562755, 'rouge2': 0.11216058456960615, 'rougeL': 0.2263330086471663, 'rougeLsum': 0.22605314047660982}\n",
      "Generated overlap 2gram = 0.759864\n",
      "Generated length = 23.501639\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.268467777969422, 'rouge2': 0.12464014082455674, 'rougeL': 0.23418868509638588, 'rougeLsum': 0.23388101956004165}\n",
      "Generated overlap 2gram = 0.815626\n",
      "Generated length = 26.877869\n",
      "\n",
      "---------------------------------- Done ----------------------------------\n",
      "\n",
      "\n",
      "experiment name : baseline_div_loss_0.1\n",
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15377611931975008, 'rouge2': 0.05892924815360488, 'rougeL': 0.1209570381795109, 'rougeLsum': 0.12097531936410129}\n",
      "Generated overlap 2gram = 0.679400\n",
      "Generated length = 86.245082\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2597816862424973, 'rouge2': 0.11220495023907201, 'rougeL': 0.22427377791050668, 'rougeLsum': 0.22401510390769352}\n",
      "Generated overlap 2gram = 0.785831\n",
      "Generated length = 23.904918\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2704905706683032, 'rouge2': 0.12708174890356277, 'rougeL': 0.2369099391371935, 'rougeLsum': 0.23654299356307268}\n",
      "Generated overlap 2gram = 0.818020\n",
      "Generated length = 26.649180\n",
      "\n",
      "---------------------------------- Done ----------------------------------\n",
      "\n",
      "\n",
      "experiment name : baseline_div_loss_0.5\n",
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15956644020718347, 'rouge2': 0.06401224384454499, 'rougeL': 0.127696213654833, 'rougeLsum': 0.12785567942654838}\n",
      "Generated overlap 2gram = 0.700229\n",
      "Generated length = 85.800820\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2668610905994591, 'rouge2': 0.11619047103506293, 'rougeL': 0.23022370739768186, 'rougeLsum': 0.23015969025006905}\n",
      "Generated overlap 2gram = 0.764636\n",
      "Generated length = 22.190164\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.26777189812869917, 'rouge2': 0.12124664186441964, 'rougeL': 0.23314744780267344, 'rougeLsum': 0.23281989992354046}\n",
      "Generated overlap 2gram = 0.808447\n",
      "Generated length = 25.182787\n",
      "\n",
      "---------------------------------- Done ----------------------------------\n",
      "\n",
      "\n",
      "experiment name : baseline_div_loss_1\n",
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15254441585930323, 'rouge2': 0.057279101658005024, 'rougeL': 0.12148196764243774, 'rougeLsum': 0.12156345269932062}\n",
      "Generated overlap 2gram = 0.687028\n",
      "Generated length = 85.757377\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.22660534700530272, 'rouge2': 0.09118497692762864, 'rougeL': 0.18894252085369206, 'rougeLsum': 0.18903445874874755}\n",
      "Generated overlap 2gram = 0.730249\n",
      "Generated length = 33.613115\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2669356094154369, 'rouge2': 0.11997088112545665, 'rougeL': 0.23067081913898924, 'rougeLsum': 0.23022259806919915}\n",
      "Generated overlap 2gram = 0.808062\n",
      "Generated length = 27.241803\n",
      "\n",
      "---------------------------------- Done ----------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_list = [\"baseline_div_loss_0\", \"baseline_div_loss_0.1\",\"baseline_div_loss_0.5\", \"baseline_div_loss_1\"]\n",
    "do_experiments(experiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15377611931975008, 'rouge2': 0.05892924815360488, 'rougeL': 0.1209570381795109, 'rougeLsum': 0.12097531936410129}\n",
      "Generated overlap 2gram = 0.679400\n",
      "Generated length = 86.245082\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2597816862424973, 'rouge2': 0.11220495023907201, 'rougeL': 0.22427377791050668, 'rougeLsum': 0.22401510390769352}\n",
      "Generated overlap 2gram = 0.785831\n",
      "Generated length = 23.904918\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2704905706683032, 'rouge2': 0.12708174890356277, 'rougeL': 0.2369099391371935, 'rougeLsum': 0.23654299356307268}\n",
      "Generated overlap 2gram = 0.818020\n",
      "Generated length = 26.649180\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_results = generate_results(exp_name = \"baseline_div_loss_0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15956644020718347, 'rouge2': 0.06401224384454499, 'rougeL': 0.127696213654833, 'rougeLsum': 0.12785567942654838}\n",
      "Generated overlap 2gram = 0.700229\n",
      "Generated length = 85.800820\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2668610905994591, 'rouge2': 0.11619047103506293, 'rougeL': 0.23022370739768186, 'rougeLsum': 0.23015969025006905}\n",
      "Generated overlap 2gram = 0.764636\n",
      "Generated length = 22.190164\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.26777189812869917, 'rouge2': 0.12124664186441964, 'rougeL': 0.23314744780267344, 'rougeLsum': 0.23281989992354046}\n",
      "Generated overlap 2gram = 0.808447\n",
      "Generated length = 25.182787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_results = generate_results(exp_name = \"baseline_div_loss_0.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold statistic\n",
      "gold overlap : 0.44 and gold length : 0.14\n",
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15254441585930323, 'rouge2': 0.057279101658005024, 'rougeL': 0.12148196764243774, 'rougeLsum': 0.12156345269932062}\n",
      "Generated overlap 2gram = 0.687028\n",
      "Generated length = 85.757377\n",
      "\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.22660534700530272, 'rouge2': 0.09118497692762864, 'rougeL': 0.18894252085369206, 'rougeLsum': 0.18903445874874755}\n",
      "Generated overlap 2gram = 0.730249\n",
      "Generated length = 33.613115\n",
      "\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2669356094154369, 'rouge2': 0.11997088112545665, 'rougeL': 0.23067081913898924, 'rougeLsum': 0.23022259806919915}\n",
      "Generated overlap 2gram = 0.808062\n",
      "Generated length = 27.241803\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_results = generate_results(exp_name = \"baseline_div_loss_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head_0': 'outputs/baseline/head_0/test_outfinal.txt', 'head_1': 'outputs/baseline/head_1/test_outfinal.txt', 'mixed': 'outputs/baseline/mixed/test_outfinal.txt'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.27271380259059985, 'rouge2': 0.11844801885694384, 'rougeL': 0.23112620936625985, 'rougeLsum': 0.23138093685586372}\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.25682834746651545, 'rouge2': 0.11131523426570167, 'rougeL': 0.22266794109804502, 'rougeLsum': 0.22259763270539173}\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.2734564229395584, 'rouge2': 0.12687083097645957, 'rougeL': 0.23668556560625628, 'rougeLsum': 0.23661751499962919}\n"
     ]
    }
   ],
   "source": [
    "filepaths = get_all_filepaths(\"outputs/baseline\")\n",
    "head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "print(\"for head 0 \")\n",
    "compute_rouge(head_0_outputs)\n",
    "print(\"for head 1\")\n",
    "compute_rouge(head_1_outputs)\n",
    "print(\"for mixed\")\n",
    "compute_rouge(mixed_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16181272918470943, 'rouge2': 0.06811278007292305, 'rougeL': 0.12751564455650777, 'rougeLsum': 0.12732488762591}\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16182719023254533, 'rouge2': 0.06813434061676622, 'rougeL': 0.12751429036211634, 'rougeLsum': 0.12732459097764445}\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.1618180191652035, 'rouge2': 0.06834181045959487, 'rougeL': 0.12745064555999921, 'rougeLsum': 0.12731014210696573}\n"
     ]
    }
   ],
   "source": [
    "filepaths = get_all_filepaths(\"outputs/exp_2\")\n",
    "head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "print(\"for head 0 \")\n",
    "compute_rouge(head_0_outputs)\n",
    "print(\"for head 1\")\n",
    "compute_rouge(head_1_outputs)\n",
    "print(\"for mixed\")\n",
    "compute_rouge(mixed_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.1608135700886158, 'rouge2': 0.06756863789155886, 'rougeL': 0.12677801594999827, 'rougeLsum': 0.12662263007161959}\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16076454316681926, 'rouge2': 0.06756053138555018, 'rougeL': 0.12675721285824504, 'rougeLsum': 0.12660349056751985}\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16097998909798306, 'rouge2': 0.06784285437698793, 'rougeL': 0.12677887221510348, 'rougeLsum': 0.12663278598260874}\n"
     ]
    }
   ],
   "source": [
    "filepaths = get_all_filepaths(\"outputs/exp_3\")\n",
    "head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "print(\"for head 0 \")\n",
    "compute_rouge(head_0_outputs)\n",
    "print(\"for head 1\")\n",
    "compute_rouge(head_1_outputs)\n",
    "print(\"for mixed\")\n",
    "compute_rouge(mixed_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for head 0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.1608135700886158, 'rouge2': 0.06756863789155886, 'rougeL': 0.12677801594999827, 'rougeLsum': 0.12662263007161959}\n",
      "for head 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16076454316681926, 'rouge2': 0.06756053138555018, 'rougeL': 0.12675721285824504, 'rougeLsum': 0.12660349056751985}\n",
      "for mixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.16097998909798306, 'rouge2': 0.06784285437698793, 'rougeL': 0.12677887221510348, 'rougeLsum': 0.12663278598260874}\n"
     ]
    }
   ],
   "source": [
    "filepaths = get_all_filepaths(\"outputs/exp_3\")\n",
    "head_0_outputs = get_paired_outputs(filepaths[\"head_0\"])\n",
    "head_1_outputs = get_paired_outputs(filepaths[\"head_1\"])\n",
    "mixed_outputs = get_paired_outputs(filepaths[\"mixed\"])\n",
    "print(\"for head 0 \")\n",
    "compute_rouge(head_0_outputs)\n",
    "print(\"for head 1\")\n",
    "compute_rouge(head_1_outputs)\n",
    "print(\"for mixed\")\n",
    "compute_rouge(mixed_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
