{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "from nltk import sent_tokenize\n",
    "import logging\n",
    "#print only errors\n",
    "import tqdm\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import json\n",
    "sys.path.append(\"./..\")\n",
    "from postprocessing.rouge import get_rouge_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.figure_factory as ffdemo\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "beam_files = [\"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_1\", \\\n",
    "              \"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_2\", \\\n",
    "              \"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_3\", \\\n",
    "              \"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_4\", \\\n",
    "              \"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_5\", \\\n",
    "              \"again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_6\"]\n",
    "           \n",
    "\n",
    "\n",
    "mixtures = [\"head_0\", \"head_1\"]\n",
    "def extract_source_reference_and_prediction(file):\n",
    "    article = []\n",
    "    reference = []\n",
    "    prediction = []\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        cur_index = 0\n",
    "        for index , line in enumerate(lines):\n",
    "            if index % 4 == 0:\n",
    "                article.append(line)\n",
    "            elif index % 4 == 1:\n",
    "                reference.append(line)\n",
    "            elif index % 4 == 2:\n",
    "                prediction.append(line)\n",
    "            elif index % 4 == 3:\n",
    "                cur_index += 1\n",
    "    return article, reference, prediction\n",
    "\n",
    "def create_all_possible_combinations(res):\n",
    "    # indexed by beam size, mixture type and article index in the dataset\n",
    "    keys = []\n",
    "    candidates = []\n",
    "    references = []\n",
    "    articles = []\n",
    "    for mixture_type in tqdm.tqdm(res.keys()):\n",
    "        if mixture_type in [\"head_0\", \"head_1\"]:\n",
    "            for index in res[mixture_type].keys():\n",
    "                article = res[mixture_type][index][\"article\"]\n",
    "                reference = res[mixture_type][index][\"reference\"]\n",
    "                for beam_size in res[mixture_type][index][\"predictions\"].keys():\n",
    "                    key = (beam_size, mixture_type, index)\n",
    "                    keys.append(key)\n",
    "                    candidates.append(res[mixture_type][str(index)][\"predictions\"][str(beam_size)])\n",
    "                    references.append(reference)\n",
    "                    articles.append(article)\n",
    "    print(len(keys))\n",
    "    print(len(candidates))\n",
    "    print(len(references))\n",
    "    print(len(articles))\n",
    "\n",
    "    return keys, candidates, references, articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixture : head_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_1\n",
      "1 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_3\n",
      "3 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_4\n",
      "4 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_6\n",
      "mixture : head_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_3\n",
      "3 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_4\n",
      "4 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 again_tests//overlap_supervision_div_loss_1_pre_lm_loss_two_head_grad_acc_10_lr_1e4_epoch_1_train_cnn_num_beam_6\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for mixture in mixtures:\n",
    "    results[mixture] = {}\n",
    "    print(\"mixture : {0}\".format(mixture))\n",
    "    for index,beam_file in tqdm.tqdm(enumerate(beam_files)):\n",
    "        print(index, beam_file)\n",
    "        mixture_folder = os.path.join(beam_file, mixture)\n",
    "        relevant_filepath = os.path.join(mixture_folder, \"test_outfinal.txt\")\n",
    "        article, reference, prediction = extract_source_reference_and_prediction(relevant_filepath)\n",
    "\n",
    "        if index == 0:\n",
    "            for idx, line in enumerate(article):\n",
    "                results[mixture][str(idx)] = {\"article\": line, \"reference\": reference[idx], \"predictions\" : {}}\n",
    "                results[mixture][str(idx)][\"predictions\"][str(index + 1)] = prediction[idx]\n",
    "        else:\n",
    "            for idx, line in enumerate(article):\n",
    "                results[mixture][str(idx)][\"predictions\"][str(index + 1)] = prediction[idx]\n",
    "            #sort the result[mixture] by index \n",
    "            results[mixture] = dict(sorted(results[mixture].items(), key=lambda x: int(x[0])))\n",
    "#save the json file\n",
    "with open(\"train_data_for_beam_size_prediction.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "unprocessed_beam_results_file = \"beam_rouge_result_unprocessed.pkl\"\n",
    "if os.path.exists(unprocessed_beam_results_file):\n",
    "    with open(unprocessed_beam_results_file, \"rb\") as f:\n",
    "        unprocessed_beam_results = pickle.load(f)\n",
    "print(len(unprocessed_beam_results.keys()))\n",
    "\n",
    "#read the json file\n",
    "with open(\"train_data_for_beam_size_prediction.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "#now combine the two \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:00<00:00, 565660.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm.tqdm(unprocessed_beam_results.keys()):\n",
    "    beam_size, mixture_type, index = key\n",
    "    if \"rouge_scores\" not in results[mixture_type][str(index)].keys():\n",
    "        results[mixture_type][str(index)]['rouge_scores'] = {str(beam_size) : unprocessed_beam_results[key]}\n",
    "    else:\n",
    "        results[mixture_type][str(index)]['rouge_scores'][str(beam_size)] = unprocessed_beam_results[key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'rouge_1_f_score': 0.30769,\n",
       "  'rouge_2_f_score': 0.22222,\n",
       "  'rouge_l_f_score': 0.18462},\n",
       " '2': {'rouge_1_f_score': 0.30303,\n",
       "  'rouge_2_f_score': 0.21875,\n",
       "  'rouge_l_f_score': 0.18182},\n",
       " '3': {'rouge_1_f_score': 0.30303,\n",
       "  'rouge_2_f_score': 0.21875,\n",
       "  'rouge_l_f_score': 0.18182},\n",
       " '4': {'rouge_1_f_score': 0.29851,\n",
       "  'rouge_2_f_score': 0.21538,\n",
       "  'rouge_l_f_score': 0.17911},\n",
       " '5': {'rouge_1_f_score': 0.29851,\n",
       "  'rouge_2_f_score': 0.21538,\n",
       "  'rouge_l_f_score': 0.17911},\n",
       " '6': {'rouge_1_f_score': 0.29851,\n",
       "  'rouge_2_f_score': 0.21538,\n",
       "  'rouge_l_f_score': 0.17911}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['head_0']['0']['rouge_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for head_0\n",
    "best = []\n",
    "worst = []\n",
    "beam_1 = []\n",
    "beam_2 = []\n",
    "beam_3 = []\n",
    "beam_4 = []\n",
    "beam_5 = []\n",
    "beam_6 = []\n",
    "for index in results['head_0'].keys():\n",
    "    scores = results['head_0'][index]['rouge_scores']\n",
    "    rouge_1_scores = [(int(k),x['rouge_1_f_score']) for k,x in scores.items()]\n",
    "    #sort by the rouge-1 score in descending order\n",
    "    beam_1.append(scores['1']['rouge_1_f_score'])\n",
    "    beam_2.append(scores['2']['rouge_1_f_score'])\n",
    "    beam_3.append(scores['3']['rouge_1_f_score'])\n",
    "    beam_4.append(scores['4']['rouge_1_f_score'])\n",
    "    beam_5.append(scores['5']['rouge_1_f_score'])\n",
    "    beam_6.append(scores['6']['rouge_1_f_score'])\n",
    "    \n",
    "    rouge_1_scores = sorted(rouge_1_scores, key=lambda x: x[1], reverse=True)\n",
    "    best_index = rouge_1_scores[0][0]\n",
    "    best_score = rouge_1_scores[0][1]\n",
    "    worst_score = rouge_1_scores[-1][1]\n",
    "\n",
    "    best.append((best_score))\n",
    "    worst.append((worst_score))\n",
    "    results['head_0'][index]['best_rouge'] = best_index\n",
    "\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4447, 3248, 1074, 595, 383, 253]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "frequency = [0 for i in range(0,7)]\n",
    "for index in results['head_0'].keys():\n",
    "    best_index = results['head_0'][index]['best_rouge']\n",
    "    frequency[best_index] += 1\n",
    "print(frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for head_1\n",
    "best = []\n",
    "worst = []\n",
    "beam_1 = []\n",
    "beam_2 = []\n",
    "beam_3 = []\n",
    "beam_4 = []\n",
    "beam_5 = []\n",
    "beam_6 = []\n",
    "for index in results['head_1'].keys():\n",
    "    scores = results['head_1'][index]['rouge_scores']\n",
    "    rouge_1_scores = [(int(k),x['rouge_1_f_score']) for k,x in scores.items()]\n",
    "    #sort by the rouge-1 score in descending order\n",
    "    beam_1.append(scores['1']['rouge_1_f_score'])\n",
    "    beam_2.append(scores['2']['rouge_1_f_score'])\n",
    "    beam_3.append(scores['3']['rouge_1_f_score'])\n",
    "    beam_4.append(scores['4']['rouge_1_f_score'])\n",
    "    beam_5.append(scores['5']['rouge_1_f_score'])\n",
    "    beam_6.append(scores['6']['rouge_1_f_score'])\n",
    "    \n",
    "    rouge_1_scores = sorted(rouge_1_scores, key=lambda x: x[1], reverse=True)\n",
    "    best_index = rouge_1_scores[0][0]\n",
    "    best_score = rouge_1_scores[0][1]\n",
    "    worst_score = rouge_1_scores[-1][1]\n",
    "\n",
    "    best.append((best_score))\n",
    "    worst.append((worst_score))\n",
    "    results['head_1'][index]['best_rouge'] = best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': \"Editor 's note : In our Behind the Scenes series , CNN correspondents share their experiences in covering news and analyze the stories behind the events . Here , Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill . An inmate housed on the `` forgotten floor , '' where many mentally ill inmates are housed in Miami before trial . MIAMI , Florida -LRB- CNN -RRB- -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the `` forgotten floor . '' Here , inmates with the most severe mental illnesses are incarcerated until they 're ready to appear in court . Most often , they face drug charges or charges of assaulting an officer -- charges that Judge Steven Leifman says are usually `` avoidable felonies . '' He says the arrests often result from confrontations with police . Mentally ill people often wo n't do what they 're told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid , delusional , and less likely to follow directions , according to Leifman . So , they end up on the ninth floor severely mentally disturbed , but not getting any real help because they 're in jail . We toured the jail with Leifman . He is well known in Miami as an advocate for justice and the mentally ill . Even though we were not exactly welcomed with open arms by the guards , we were given permission to shoot videotape and tour the floor . Go inside the ` forgotten floor ' '' At first , it 's hard to determine where the people are . The prisoners are wearing sleeveless robes . Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that 's kind of what they look like . They 're designed to keep the mentally ill patients from injuring themselves . That 's also why they have no shoes , laces or mattresses . Leifman says about one-third of all people in Miami-Dade county jails are mentally ill . So , he says , the sheer volume is overwhelming the system , and the result is what we see on the ninth floor . Of course , it is a jail , so it 's not supposed to be warm and comforting , but the lights glare , the cells are tiny and it 's loud . We see two , sometimes three men -- sometimes in the robes , sometimes naked , lying or sitting in their cells . `` I am the son of the president . You need to get me out of here ! '' one man shouts at me . He is absolutely serious , convinced that help is on the way -- if only he could reach the White House . Leifman tells me that these prisoner-patients will often circulate through the system , occasionally stabilizing in a mental hospital , only to return to jail to face their charges . It 's brutally unjust , in his mind , and he has become a strong advocate for changing things in Miami . Over a meal later , we talk about how things got this way for mental patients . Leifman says 200 years ago people were considered `` lunatics '' and they were locked up in jails even if they had no charges against them . They were just considered unfit to be in society . Over the years , he says , there was some public outcry , and the mentally ill were moved out of jails and into hospitals . But Leifman says many of these mental hospitals were so horrible they were shut down . Where did the patients go ? Nowhere . The streets . They became , in many cases , the homeless , he says . They never got treatment . Leifman says in 1955 there were more than half a million people in state mental hospitals , and today that number has been reduced 90 percent , and 40,000 to 50,000 people are in mental hospitals . The judge says he 's working to change this . Starting in 2008 , many inmates who would otherwise have been brought to the `` forgotten floor '' will instead be sent to a new mental health facility -- the first step on a journey toward long-term treatment , not just punishment . Leifman says it 's not the complete answer , but it 's a start . Leifman says the best part is that it 's a win-win solution . The patients win , the families are relieved , and the state saves money by simply not cycling these prisoners through again and again . And , for Leifman , justice is served . E-mail to a friend .\\n\",\n",
       " 'reference': \"Mentally ill inmates in Miami are housed on the `` forgotten floor '' Judge Steven Leifman says most are there as a result of `` avoidable felonies '' While CNN tours facility , patient shouts : `` I am the son of the president '' Leifman says the system is unjust and he 's fighting for change .\\n\",\n",
       " 'predictions': {'1': 'About one-third of all people in Miami-Dade county jails are mentally ill .\\n',\n",
       "  '2': 'About one-third of all people in Miami-Dade county jails are mentally ill .\\n',\n",
       "  '3': 'About one-third of all people in Miami-Dade county jails are mentally ill .\\n',\n",
       "  '4': 'About one-third of all people in Miami-Dade county jails are mentally ill .\\n',\n",
       "  '5': 'About one-third of all people in Miami-Dade county jails are mentally ill , judge says .\\n',\n",
       "  '6': 'About one-third of all people in Miami-Dade county jails are mentally ill , judge says .\\n'},\n",
       " 'rouge_scores': {'1': {'rouge_1_f_score': 0.19048,\n",
       "   'rouge_2_f_score': 0.06558,\n",
       "   'rouge_l_f_score': 0.09523},\n",
       "  '2': {'rouge_1_f_score': 0.19048,\n",
       "   'rouge_2_f_score': 0.06558,\n",
       "   'rouge_l_f_score': 0.09523},\n",
       "  '3': {'rouge_1_f_score': 0.19048,\n",
       "   'rouge_2_f_score': 0.06558,\n",
       "   'rouge_l_f_score': 0.09523},\n",
       "  '4': {'rouge_1_f_score': 0.19048,\n",
       "   'rouge_2_f_score': 0.06558,\n",
       "   'rouge_l_f_score': 0.09523},\n",
       "  '5': {'rouge_1_f_score': 0.24616,\n",
       "   'rouge_2_f_score': 0.0635,\n",
       "   'rouge_l_f_score': 0.15385},\n",
       "  '6': {'rouge_1_f_score': 0.24616,\n",
       "   'rouge_2_f_score': 0.0635,\n",
       "   'rouge_l_f_score': 0.15385}},\n",
       " 'best_rouge': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['head_1']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.426626264\n",
      "0.26948863199999995\n",
      "0.33827261799999997\n",
      "0.351188635\n",
      "0.352801064\n",
      "0.352877055\n",
      "0.35148168\n",
      "0.352945295\n"
     ]
    }
   ],
   "source": [
    "print(np.average(best))\n",
    "print(np.average(worst))\n",
    "print(np.average(beam_1))\n",
    "print(np.average(beam_2))\n",
    "print(np.average(beam_3))\n",
    "print(np.average(beam_4))\n",
    "print(np.average(beam_5))\n",
    "print(np.average(beam_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15713763199999997\n"
     ]
    }
   ],
   "source": [
    "diff = [best[i] - worst[i] for i in range(len(best))]\n",
    "print(np.average(diff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"train_data_for_beam_size_prediction_with_rouge_scores.json\"\n",
    "#save as a pickle file\n",
    "with open(save_file, \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "2000\n",
      "8000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#split head 0 and head 1 into 80/20 for training and testing\n",
    "train_head_0_filepath = \"./train_head_0.pkl\"\n",
    "train_head_1_filepath = \"./train_head_1.pkl\"\n",
    "\n",
    "valid_head_0_filepath = \"./valid_head_0.pkl\"\n",
    "valid_head_1_filepath = \"./valid_head_1.pkl\"\n",
    "\n",
    "#head 0\n",
    "head_0 = results['head_0']\n",
    "head_0_keys = list(head_0.keys())\n",
    "\n",
    "#shuffle the keys\n",
    "random.shuffle(head_0_keys)\n",
    "\n",
    "#split into 80/20\n",
    "train_head_0_data = {k:head_0[k] for k in head_0_keys[:int(0.8*len(head_0_keys))]}\n",
    "valid_head_0_data = {k:head_0[k] for k in head_0_keys[int(0.8*len(head_0_keys)):]}\n",
    "\n",
    "print(len(train_head_0_data.keys()))\n",
    "print(len(valid_head_0_data.keys()))\n",
    "\n",
    "#now head 1\n",
    "head_1 = results['head_1']\n",
    "head_1_keys = list(head_1.keys())\n",
    "\n",
    "#shuffle the keys\n",
    "random.shuffle(head_1_keys)\n",
    "\n",
    "#split into 80/20\n",
    "train_head_1_data = {k:head_1[k] for k in head_1_keys[:int(0.8*len(head_1_keys))]}\n",
    "valid_head_1_data = {k:head_1[k] for k in head_1_keys[int(0.8*len(head_1_keys)):]}\n",
    "\n",
    "print(len(train_head_1_data.keys()))\n",
    "print(len(valid_head_1_data.keys()))\n",
    "\n",
    "#save all the files as json \n",
    "with open(train_head_0_filepath, \"wb\") as f:\n",
    "    pickle.dump(train_head_0_data, f)\n",
    "with open(train_head_1_filepath, \"wb\") as f:\n",
    "    pickle.dump(train_head_1_data, f)\n",
    "with open(valid_head_0_filepath, \"wb\") as f:\n",
    "    pickle.dump(valid_head_0_data, f)\n",
    "with open(valid_head_1_filepath, \"wb\") as f:\n",
    "    pickle.dump(valid_head_1_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
